import { NextRequest, NextResponse } from 'next/server'
import { errorTracker } from './error-tracker'

export interface PerformanceMetrics {
  path: string
  method: string
  duration: number
  statusCode: number
  timestamp: Date
  userAgent?: string
  ip?: string
  userId?: string
  memoryUsage?: {
    heapUsed: number
    heapTotal: number
  }
}

export interface PerformanceStats {
  totalRequests: number
  averageResponseTime: number
  maxResponseTime: number
  minResponseTime: number
  slowRequests: number
  errorRate: number
  requestsByPath: Record<string, number>
  requestsByStatus: Record<number, number>
}

/**
 * æ€§èƒ½ç›‘æ§ç³»ç»Ÿ
 * è®°å½•å’Œåˆ†æAPIè¯·æ±‚çš„æ€§èƒ½æŒ‡æ ‡
 */
export class PerformanceMonitor {
  private metrics: PerformanceMetrics[] = []
  private maxMetrics: number
  private slowRequestThreshold: number

  constructor() {
    this.maxMetrics = parseInt(process.env.MAX_PERFORMANCE_METRICS || '1000')
    this.slowRequestThreshold = parseInt(process.env.SLOW_REQUEST_THRESHOLD || '2000')
  }

  /**
   * è®°å½•è¯·æ±‚æ€§èƒ½æŒ‡æ ‡
   */
  recordMetric(metric: PerformanceMetrics): void {
    this.metrics.push(metric)
    
    // ä¿æŒæœ€è¿‘Næ¡è®°å½•
    if (this.metrics.length > this.maxMetrics) {
      this.metrics = this.metrics.slice(-this.maxMetrics)
    }
    
    // æ…¢è¯·æ±‚å‘Šè­¦
    if (metric.duration > this.slowRequestThreshold) {
      this.handleSlowRequest(metric)
    }

    // é”™è¯¯è¯·æ±‚è®°å½•
    if (metric.statusCode >= 500) {
      this.handleErrorRequest(metric)
    }
  }

  /**
   * åˆ›å»ºæ€§èƒ½ç›‘æ§ä¸­é—´ä»¶
   */
  createMiddleware() {
    return async (request: NextRequest, response: NextResponse) => {
      const startTime = Date.now()
      const startMemory = process.memoryUsage()

      // è·å–è¯·æ±‚ä¿¡æ¯
      const path = new URL(request.url).pathname
      const method = request.method
      const userAgent = request.headers.get('user-agent') || undefined
      const ip = this.getClientIP(request)

      try {
        // ç»§ç»­å¤„ç†è¯·æ±‚
        const result = response

        // è®°å½•æ€§èƒ½æŒ‡æ ‡
        const endTime = Date.now()
        const endMemory = process.memoryUsage()
        
        const metric: PerformanceMetrics = {
          path,
          method,
          duration: endTime - startTime,
          statusCode: result.status,
          timestamp: new Date(),
          userAgent,
          ip,
          memoryUsage: {
            heapUsed: endMemory.heapUsed - startMemory.heapUsed,
            heapTotal: endMemory.heapTotal
          }
        }

        this.recordMetric(metric)
        
        return result
      } catch (error) {
        // è®°å½•é”™è¯¯è¯·æ±‚
        const metric: PerformanceMetrics = {
          path,
          method,
          duration: Date.now() - startTime,
          statusCode: 500,
          timestamp: new Date(),
          userAgent,
          ip
        }

        this.recordMetric(metric)
        throw error
      }
    }
  }

  /**
   * è·å–æ€§èƒ½ç»Ÿè®¡
   */
  getStats(timeRange?: { start: Date; end: Date }): PerformanceStats {
    let filteredMetrics = this.metrics

    // æ—¶é—´èŒƒå›´è¿‡æ»¤
    if (timeRange) {
      filteredMetrics = this.metrics.filter(
        m => m.timestamp >= timeRange.start && m.timestamp <= timeRange.end
      )
    }

    if (filteredMetrics.length === 0) {
      return {
        totalRequests: 0,
        averageResponseTime: 0,
        maxResponseTime: 0,
        minResponseTime: 0,
        slowRequests: 0,
        errorRate: 0,
        requestsByPath: {},
        requestsByStatus: {}
      }
    }

    const durations = filteredMetrics.map(m => m.duration)
    const avgDuration = durations.reduce((a, b) => a + b, 0) / durations.length
    const maxDuration = Math.max(...durations)
    const minDuration = Math.min(...durations)
    const slowRequests = filteredMetrics.filter(m => m.duration > this.slowRequestThreshold).length
    const errorRequests = filteredMetrics.filter(m => m.statusCode >= 400).length

    // æŒ‰è·¯å¾„ç»Ÿè®¡
    const requestsByPath: Record<string, number> = {}
    filteredMetrics.forEach(m => {
      requestsByPath[m.path] = (requestsByPath[m.path] || 0) + 1
    })

    // æŒ‰çŠ¶æ€ç ç»Ÿè®¡
    const requestsByStatus: Record<number, number> = {}
    filteredMetrics.forEach(m => {
      requestsByStatus[m.statusCode] = (requestsByStatus[m.statusCode] || 0) + 1
    })

    return {
      totalRequests: filteredMetrics.length,
      averageResponseTime: Math.round(avgDuration),
      maxResponseTime: maxDuration,
      minResponseTime: minDuration,
      slowRequests,
      errorRate: Math.round((errorRequests / filteredMetrics.length) * 100),
      requestsByPath,
      requestsByStatus
    }
  }

  /**
   * è·å–æœ€è¿‘çš„æ…¢è¯·æ±‚
   */
  getSlowRequests(limit: number = 10): PerformanceMetrics[] {
    return this.metrics
      .filter(m => m.duration > this.slowRequestThreshold)
      .sort((a, b) => b.duration - a.duration)
      .slice(0, limit)
  }

  /**
   * è·å–é”™è¯¯è¯·æ±‚
   */
  getErrorRequests(limit: number = 10): PerformanceMetrics[] {
    return this.metrics
      .filter(m => m.statusCode >= 400)
      .sort((a, b) => b.timestamp.getTime() - a.timestamp.getTime())
      .slice(0, limit)
  }

  /**
   * è·å–çƒ­é—¨è·¯å¾„
   */
  getPopularPaths(limit: number = 10): Array<{ path: string; count: number; avgDuration: number }> {
    const pathStats = new Map<string, { count: number; totalDuration: number }>()

    this.metrics.forEach(metric => {
      const existing = pathStats.get(metric.path) || { count: 0, totalDuration: 0 }
      pathStats.set(metric.path, {
        count: existing.count + 1,
        totalDuration: existing.totalDuration + metric.duration
      })
    })

    return Array.from(pathStats.entries())
      .map(([path, stats]) => ({
        path,
        count: stats.count,
        avgDuration: Math.round(stats.totalDuration / stats.count)
      }))
      .sort((a, b) => b.count - a.count)
      .slice(0, limit)
  }

  /**
   * æ¸…ç†æ—§æŒ‡æ ‡
   */
  cleanup(olderThan: Date): number {
    const initialLength = this.metrics.length
    this.metrics = this.metrics.filter(m => m.timestamp > olderThan)
    return initialLength - this.metrics.length
  }

  /**
   * å¤„ç†æ…¢è¯·æ±‚
   */
  private async handleSlowRequest(metric: PerformanceMetrics): Promise<void> {
    console.warn(`ğŸŒ æ…¢è¯·æ±‚æ£€æµ‹: ${metric.method} ${metric.path} - ${metric.duration}ms`)
    
    // è®°å½•æ…¢è¯·æ±‚æ—¥å¿—
    await errorTracker.logWarning(`æ…¢è¯·æ±‚æ£€æµ‹: ${metric.method} ${metric.path}`, {
      duration: metric.duration,
      threshold: this.slowRequestThreshold,
      path: metric.path,
      method: metric.method,
      statusCode: metric.statusCode,
      userAgent: metric.userAgent,
      ip: metric.ip
    })
  }

  /**
   * å¤„ç†é”™è¯¯è¯·æ±‚
   */
  private async handleErrorRequest(metric: PerformanceMetrics): Promise<void> {
    await errorTracker.logError({
      id: `perf-error-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
      timestamp: metric.timestamp,
      level: 'error',
      message: `HTTPé”™è¯¯: ${metric.statusCode} ${metric.method} ${metric.path}`,
      context: {
        path: metric.path,
        method: metric.method,
        statusCode: metric.statusCode,
        duration: metric.duration,
        userAgent: metric.userAgent,
        ip: metric.ip,
        memoryUsage: metric.memoryUsage
      }
    })
  }

  /**
   * è·å–å®¢æˆ·ç«¯IPåœ°å€
   */
  private getClientIP(request: NextRequest): string | undefined {
    // å°è¯•ä»å„ç§å¤´éƒ¨è·å–çœŸå®IP
    const forwarded = request.headers.get('x-forwarded-for')
    if (forwarded) {
      return forwarded.split(',')[0].trim()
    }

    const realIP = request.headers.get('x-real-ip')
    if (realIP) {
      return realIP
    }

    const cfConnectingIP = request.headers.get('cf-connecting-ip')
    if (cfConnectingIP) {
      return cfConnectingIP
    }

    // ä»è¯·æ±‚å¯¹è±¡è·å–IPï¼ˆåœ¨æŸäº›ç¯å¢ƒä¸­å¯èƒ½ä¸å¯ç”¨ï¼‰
    return undefined
  }
}

// å¯¼å‡ºå•ä¾‹å®ä¾‹
export const performanceMonitor = new PerformanceMonitor()

/**
 * Next.jsä¸­é—´ä»¶åŒ…è£…å™¨
 */
export function withPerformanceMonitoring<T extends any[], R>(
  handler: (...args: T) => Promise<R>,
  context: { path: string; method: string }
): (...args: T) => Promise<R> {
  return async (...args: T): Promise<R> => {
    const startTime = Date.now()
    const startMemory = process.memoryUsage()

    try {
      const result = await handler(...args)
      
      // è®°å½•æˆåŠŸè¯·æ±‚
      const metric: PerformanceMetrics = {
        path: context.path,
        method: context.method,
        duration: Date.now() - startTime,
        statusCode: 200,
        timestamp: new Date(),
        memoryUsage: {
          heapUsed: process.memoryUsage().heapUsed - startMemory.heapUsed,
          heapTotal: process.memoryUsage().heapTotal
        }
      }

      performanceMonitor.recordMetric(metric)
      return result
    } catch (error) {
      // è®°å½•é”™è¯¯è¯·æ±‚
      const metric: PerformanceMetrics = {
        path: context.path,
        method: context.method,
        duration: Date.now() - startTime,
        statusCode: 500,
        timestamp: new Date(),
        memoryUsage: {
          heapUsed: process.memoryUsage().heapUsed - startMemory.heapUsed,
          heapTotal: process.memoryUsage().heapTotal
        }
      }

      performanceMonitor.recordMetric(metric)
      throw error
    }
  }
}